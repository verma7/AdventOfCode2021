{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkOORXWUfJIkYN+McXOPg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma7/AdventOfCode2021/blob/master/RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vjd1M1WkWU5R"
      },
      "outputs": [],
      "source": [
        "# RL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]\n",
        "!pip install tf-keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-0x0yNuWqi0",
        "outputId": "5040ab00-cb3b-4936-a9ff-bf836df3dec4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.19.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (3.1.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents[reverb])\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (11.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (4.25.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from tf-agents[reverb]) (1.17.2)\n",
            "Collecting typing-extensions==4.5.0 (from tf-agents[reverb])\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pygame==2.1.3 (from tf-agents[reverb])\n",
            "  Downloading pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting tensorflow-probability~=0.23.0 (from tf-agents[reverb])\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rlds (from tf-agents[reverb])\n",
            "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting dm-reverb~=0.14.0 (from tf-agents[reverb])\n",
            "  Downloading dm_reverb-0.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting tensorflow~=2.15.0 (from tf-agents[reverb])\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (0.1.9)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.11/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.15.0->tf-agents[reverb])\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.5.0)\n",
            "Collecting wrapt>=1.11.1 (from tf-agents[reverb])\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.70.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow~=2.15.0->tf-agents[reverb])\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-agents[reverb])\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-agents[reverb])\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.23.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.1.3)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->dm-reverb~=0.14.0->tf-agents[reverb]) (25.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.2.2)\n",
            "Downloading pygame-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading dm_reverb-0.14.0-cp311-cp311-manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_agents-0.19.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697712 sha256=e4e1b70e177b44562960128fc46af1ae1e5cfc6823ab1d578fd5139fb0e4680c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/19/ce/d2b762b6d61115bf0b4260ca59650ba2d55d49f34f61e095f6\n",
            "Successfully built gym\n",
            "Installing collected packages: wrapt, typing-extensions, tensorflow-estimator, rlds, pygame, ml-dtypes, keras, gym, tensorflow-probability, dm-reverb, tf-agents, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.6.1\n",
            "    Uninstalling pygame-2.6.1:\n",
            "      Successfully uninstalled pygame-2.6.1\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "langchain-core 0.3.37 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sqlalchemy 2.0.38 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.27.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.61.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dm-reverb-0.14.0 gym-0.23.0 keras-2.15.0 ml-dtypes-0.3.2 pygame-2.1.3 rlds-0.1.8 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-probability-0.23.0 tf-agents-0.19.0 typing-extensions-4.5.0 wrapt-1.14.1\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow<2.19,>=2.18 (from tf-keras)\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18->tf-keras)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
            "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
            "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.1\n",
            "    Uninstalling tensorflow-2.15.1:\n",
            "      Successfully uninstalled tensorflow-2.15.1\n",
            "Successfully installed keras-3.8.0 ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ],
      "metadata": {
        "id": "MT59_Qw0XPiQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install galois"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFA9JVKfaQ4p",
        "outputId": "ae48163b-ca6a-4535-a18f-8848201b8e1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting galois\n",
            "  Downloading galois-0.4.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from galois) (1.26.4)\n",
            "Requirement already satisfied: numba<0.62,>=0.55 in /usr/local/lib/python3.11/dist-packages (from galois) (0.61.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from galois) (4.5.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.62,>=0.55->galois) (0.44.0)\n",
            "Downloading galois-0.4.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: galois\n",
            "Successfully installed galois-0.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import galois\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "\n",
        "from tf_agents.policies import random_py_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.metrics import py_metrics\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.drivers import dynamic_episode_driver\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "\n",
        "from tf_agents import specs\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.replay_buffers import py_uniform_replay_buffer\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.trajectories import time_step\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common\n",
        "\n",
        "from tf_agents.train.utils import strategy_utils\n"
      ],
      "metadata": {
        "id": "0CtpTB0KXSUx"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_ones(w):\n",
        "    \"Returns a vector containing the number of ones in the bit representation in each element of the GF(2^w) field.\"\n",
        "    N = 2 ** w\n",
        "    GF = galois.GF(N)\n",
        "    num_ones = np.zeros(N)\n",
        "    for i in range(N):\n",
        "        for j in range(w):\n",
        "            v = np.multiply(GF(i), GF(2 ** j))\n",
        "            num_ones[i] += bin(v).count(\"1\")\n",
        "    return num_ones\n",
        "\n",
        "def count_ones(GC, n, m, ones):\n",
        "    sum_ones = 0\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            sum_ones += ones[int(GC[i][j])]\n",
        "    return sum_ones\n",
        "\n",
        "def swap(x, y, state_x, state_y, state):\n",
        "  xi = 0\n",
        "  for i in range(len(state)):\n",
        "    if state[i] == state_x:\n",
        "      if xi == x:\n",
        "        break\n",
        "      xi += 1\n",
        "\n",
        "  xj = 0\n",
        "  for j in range(len(state)):\n",
        "    if state[j] == state_y:\n",
        "      if xj == y:\n",
        "        break\n",
        "      xj += 1\n",
        "\n",
        "  tmp = state[i]\n",
        "  state[i] = state[j]\n",
        "  state[j] = tmp\n",
        "\n",
        "def normalize_bitmatrix(GF, GC, m, ONES):\n",
        "  # Make the first row 1s by dividing all the columns by its first element.\n",
        "  M = np.zeros((m, m))\n",
        "  for i in range(m):\n",
        "      for j in range(m):\n",
        "          if GC[0][j] == 0:\n",
        "              continue\n",
        "          M[i][j] = np.divide(GF(int(GC[i][j])), GF(int(GC[0][j])))\n",
        "#    print(M)\n",
        "\n",
        "  # For each row, pick one of the elements that minimizes the number of ones and divide the row by it.\n",
        "  for i in range(1, m):\n",
        "      min_ones = 1e8\n",
        "      best_C = None\n",
        "\n",
        "      for j in range(m):\n",
        "          if M[i][j] == 0:\n",
        "              continue\n",
        "\n",
        "          C = np.zeros(m)\n",
        "          sum_ones = 0\n",
        "          C_ones = []\n",
        "          for k in range(m):\n",
        "              C[k] = np.divide(GF(int(M[i][k])), GF(int(M[i][j])))\n",
        "              sum_ones += ONES[int(C[k])]\n",
        "              C_ones.append(ONES[int(C[k])])\n",
        "          if sum_ones < min_ones:\n",
        "              min_ones = sum_ones\n",
        "              best_C = C\n",
        "      for j in range(m):\n",
        "          if best_C is not None:\n",
        "              M[i][j] = best_C[j]\n",
        "  return M\n",
        "\n",
        "def good_cauchy_matrix(GF, m, N, state):\n",
        "  GC = np.zeros((m, m))\n",
        "  x = 0\n",
        "  y = 0\n",
        "  for i in range(N):\n",
        "      if state[i] == 0:\n",
        "        y = 0\n",
        "        for j in range(N):\n",
        "            if state[j] == 1:\n",
        "              sum = GF(i) + GF(j)\n",
        "              if sum == 0:\n",
        "                  continue\n",
        "              GC[x][y] = sum ** -1\n",
        "              y += 1\n",
        "        x += 1\n",
        "  return GC\n",
        "\n",
        "def simulate_action(action, m, N, state, GF, ONES):\n",
        "  max_action = m * m + 2 * m * N - 1\n",
        "  if action < 0 or action > max_action:\n",
        "    raise ValueError(f'`action` should be between [0, {max_action}), but is {action}')\n",
        "  elif action < m * m:\n",
        "    x = action // m\n",
        "    y = action % m\n",
        "    swap(x, y, 0, 1, state)\n",
        "  elif action < m * m + m * N:\n",
        "    denom = m * N\n",
        "    offset = m * m\n",
        "    x = (action - offset) // denom\n",
        "    y = (action - offset) % denom\n",
        "    swap(x, y, 0, 2, state)\n",
        "  elif action < m * m + 2 * m * N:\n",
        "    denom = m * N\n",
        "    offset = m * m + m * N\n",
        "    x = (action - offset) // denom\n",
        "    y = (action - offset) % denom\n",
        "    swap(x, y, 1, 2, state)\n",
        "  else:\n",
        "    raise ValueError(f'`action` should be between [0, {max_action}), but is {action}')\n",
        "\n",
        "  GC = good_cauchy_matrix(GF, m, N, state)\n",
        "  NGC = normalize_bitmatrix(GF, GC, m, ONES)\n",
        "  return count_ones(NGC, m, m, ONES)\n",
        "\n",
        "def stochastic_hill_climbing_action(w, m, N, state, num_ones):\n",
        "  \"\"\"Returns an action\"\"\"\n",
        "  max_action = m * m + 2 * m * N - 1\n",
        "  GF = galois.GF(N)\n",
        "  ONES = get_num_ones(w)\n",
        "\n",
        "  GC = good_cauchy_matrix(GF, m, N, state)\n",
        "  NGC = normalize_bitmatrix(GF, GC, m, ONES)\n",
        "  actions = [action for action in range(max_action + 1)]\n",
        "  random.shuffle(actions)\n",
        "  for action in actions:\n",
        "    state_copy = state.copy()\n",
        "    sim_num_ones = simulate_action(action, m, N, state_copy, GF, ONES)\n",
        "    reward = num_ones - sim_num_ones\n",
        "    # print(f'action = {action}, reward = {reward}, prev num_ones = {num_ones}, sim num ones = {sim_num_ones}')\n",
        "    if reward > 0:\n",
        "      return action\n",
        "  return -1\n",
        "\n",
        "def simulated_annealing_action(w, m, N, state, num_ones, temperature):\n",
        "  \"\"\"Returns an action\"\"\"\n",
        "  max_action = m * m + 2 * m * N - 1\n",
        "  GF = galois.GF(N)\n",
        "  ONES = get_num_ones(w)\n",
        "\n",
        "  GC = good_cauchy_matrix(GF, m, N, state)\n",
        "  NGC = normalize_bitmatrix(GF, GC, m, ONES)\n",
        "  actions = [action for action in range(max_action + 1)]\n",
        "  random.shuffle(actions)\n",
        "\n",
        "  weights = np.zeros(max_action + 1)\n",
        "  for action in actions:\n",
        "    state_copy = state.copy()\n",
        "    sim_num_ones = simulate_action(action, m, N, state_copy, GF, ONES)\n",
        "    reward = num_ones - sim_num_ones\n",
        "    weights[action] = reward\n",
        "    # print(f'action = {action}, reward = {reward}, prev num_ones = {num_ones}, sim num ones = {sim_num_ones}')\n",
        "    metropolis = math.exp(reward / temperature)\n",
        "    if reward > 0 or random.random() < metropolis:\n",
        "      return action\n",
        "  return -1\n",
        "\n",
        "def construct_state(vec, m, N):\n",
        "  state = [0] * N\n",
        "  for i in vec[:m]:\n",
        "      state[i] = 0\n",
        "  for i in vec[m:2*m]:\n",
        "      state[i] = 1\n",
        "  for i in vec[2*m:]:\n",
        "      state[i] = 2\n",
        "  return state"
      ],
      "metadata": {
        "id": "r9Fwcjv-aJQI"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_population(population_size, m, N):\n",
        "  pop = []\n",
        "  vec = [ i for i in range(N)]\n",
        "  for i in range(population_size):\n",
        "    random.shuffle(vec)\n",
        "    state = construct_state(vec, m, N)\n",
        "    pop.append(state)\n",
        "  return pop\n",
        "\n",
        "def compute_fitness(individual, GF, m, N, w, ONES):\n",
        "  GC = good_cauchy_matrix(GF, m, N, individual)\n",
        "  NGC = normalize_bitmatrix(GF, GC, m, ONES)\n",
        "  ones = count_ones(NGC, m, m, ONES)\n",
        "  return m * m * w * w - ones, ones\n",
        "\n",
        "def crossover(x, y, m):\n",
        "  # print(f'Crossover: {x}, {y}')\n",
        "\n",
        "  assert len(x) == len(y)\n",
        "  N = len(x)\n",
        "  new = np.full(N, 2)\n",
        "  remaining = set()\n",
        "\n",
        "  num_0 = 0\n",
        "  num_1 = 0\n",
        "  for i in range(N):\n",
        "    if x[i] == y[i]:\n",
        "        new[i] = x[i]\n",
        "        if x[i] == 0:\n",
        "          num_0 += 1\n",
        "        elif x[i] == 1:\n",
        "          num_1 += 1\n",
        "    elif x[i] in [0, 1] or y[i] in [0, 1]:\n",
        "      remaining.add(i)\n",
        "\n",
        "  remaining = list(remaining)\n",
        "  random.shuffle(remaining)\n",
        "\n",
        "  k = 0\n",
        "  for i in range(num_0, m):\n",
        "      new[remaining[k]] = 0\n",
        "      k += 1\n",
        "  for j in range(num_1, m):\n",
        "      new[remaining[k]] = 1\n",
        "      k += 1\n",
        "\n",
        "  return new\n",
        "\n",
        "def genetic_algorithm(w, m):\n",
        "  N = 2 ** w\n",
        "  population_size = 5\n",
        "  num_generations = 1000\n",
        "  mutation_rate = 0.1\n",
        "\n",
        "  GF = galois.GF(N)\n",
        "  ONES = get_num_ones(w)\n",
        "\n",
        "  population = create_population(population_size, m, N)\n",
        "  print(population)\n",
        "\n",
        "  best_ones = 1e8\n",
        "  for i in range(num_generations):\n",
        "    fitnesses = []\n",
        "    for individual in population:\n",
        "      fitness, ones = compute_fitness(individual, GF, m, N, w, ONES)\n",
        "      if ones < best_ones:\n",
        "        best_ones = ones\n",
        "        print(f'generation = {i}, best ones = {best_ones}')\n",
        "      fitnesses.append(fitness)\n",
        "#      print(f'Individual: {individual}, fitness: {fitness}, ones: {ones}')\n",
        "\n",
        "      if random.random() < mutation_rate:\n",
        "        action = random.randint(0, m * m + 2 * m * N - 1)\n",
        "        # print(f'Action: {action}')\n",
        "        # print(f'Old individual = {individual}')\n",
        "        simulate_action(action, m, N, individual, GF, ONES)\n",
        "        # print(f'New individual = {individual}')\n",
        "\n",
        "    new_population = []\n",
        "    weights = np.array(fitnesses)\n",
        "    weights = weights / np.sum(weights)\n",
        "    indices = np.arange(population_size)\n",
        "    for i in range(population_size):\n",
        "      selected = np.random.choice(indices, p=weights, size=2, replace=False)\n",
        "      new_population.append(crossover(population[selected[0]], population[selected[1]], m))\n",
        "    population = new_population\n",
        "\n",
        "genetic_algorithm(8, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yikkW8oHyuwW",
        "outputId": "acd0b6e0-d5ba-4cc1-c732-b2f80611e66d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2], [2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2]]\n",
            "generation = 0, best ones = 810.0\n",
            "generation = 0, best ones = 751.0\n",
            "generation = 485, best ones = 737.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CauchyEnv(py_environment.PyEnvironment):\n",
        "\n",
        "  def __init__(self, W, m, vec, num_ones_list):\n",
        "    self._W = W\n",
        "    self._N = 2 ** self._W\n",
        "    self._m = m\n",
        "    self._GF = galois.GF(self._N)\n",
        "    self._ONES = get_num_ones(self._w)\n",
        "    self._num_ones_list = num_ones_list\n",
        "\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int64, minimum=0, maximum=self._m * self._m + 2 * self._m * self._N - 1, name='action')\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(self._N, ), dtype=np.int32, minimum=0, maximum=2, name='observation')\n",
        "    self._initialize(vec)\n",
        "\n",
        "  def _initialize(self, vec):\n",
        "    self._best_num_ones = 1e8\n",
        "    self._vec = vec\n",
        "    self._state = construct_state(self._vec, self._m, self._N)\n",
        "    self._GC = good_cauchy_matrix(self._GF, self._m, self._N, self._state)\n",
        "    NGC = normalize_bitmatrix(self._GF, self._GC, self._m, self._ONES)\n",
        "    self._num_ones = count_ones(NGC, self._m, self._m, self._ONES)\n",
        "    self._best_num_ones = self._num_ones\n",
        "    self._time_steps_without_improvement = 0\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _reset(self):\n",
        "    self._initialize(self._vec)\n",
        "    return ts.restart(np.array(self._state, dtype=np.int32))\n",
        "\n",
        "  def _step(self, action):\n",
        "    new_num_ones = simulate_action(action, self._m, self._N, self._state, self._GF, self._ONES)\n",
        "    reward = self._num_ones - new_num_ones\n",
        "    self._num_ones = new_num_ones\n",
        "    self._num_ones_list.append(new_num_ones)\n",
        "    if new_num_ones < self._best_num_ones:\n",
        "      self._best_num_ones = new_num_ones\n",
        "      # print(f'Best num ones = {new_num_ones}')\n",
        "      self._time_steps_without_improvement = 0\n",
        "    else:\n",
        "      self._time_steps_without_improvement += 1\n",
        "    # print(f'Time steps without improvement: {self._time_steps_without_improvement}, best num ones = {self._best_num_ones}')\n",
        "    if self._time_steps_without_improvement == 10:\n",
        "      self._time_steps_without_improvement = 0\n",
        "      self._initialize(self._vec)\n",
        "      return ts.termination(np.array(self._state, dtype=np.int32), reward)\n",
        "    else:\n",
        "      return ts.transition(np.array(self._state, dtype=np.int32), reward=reward, discount=1.0)"
      ],
      "metadata": {
        "id": "BXCAiZLnXfF4"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = 5\n",
        "m = 5\n",
        "N = 2 ** w\n",
        "# Random restart stochastic hill climbing\n",
        "vec = [ i for i in range(N)]\n",
        "random.shuffle(vec)\n",
        "\n",
        "\n",
        "max_episodes = 10\n",
        "num_episodes = 0\n",
        "\n",
        "num_ones = []\n",
        "env = CauchyEnv(w, m, vec, num_ones)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "while (num_episodes < max_episodes):\n",
        "  time_step = tf_env.reset()\n",
        "  num_episodes += 1\n",
        "  num_ones.clear()\n",
        "\n",
        "  while not time_step.is_last():\n",
        "    action = stochastic_hill_climbing_action(env._w, env._m, env._N, env._state, env._num_ones)\n",
        "    if action == -1:\n",
        "      break\n",
        "    time_step = tf_env.step(action)\n",
        "\n",
        "  if num_ones:\n",
        "    print(num_ones)\n",
        "    print(f'Min num_ones: {np.min(num_ones)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V0foyl2x1BY",
        "outputId": "336b28bb-5f88-43c2-ee60-86f84b77d5c4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[224.0, 214.0, 212.0, 209.0, 208.0]\n",
            "Min num_ones: 208.0\n",
            "[213.0, 207.0, 204.0, 198.0, 194.0, 185.0]\n",
            "Min num_ones: 185.0\n",
            "[213.0, 207.0, 205.0, 197.0]\n",
            "Min num_ones: 197.0\n",
            "[224.0, 214.0, 213.0, 211.0, 209.0, 198.0]\n",
            "Min num_ones: 198.0\n",
            "[224.0, 204.0, 203.0]\n",
            "Min num_ones: 203.0\n",
            "[222.0, 214.0, 212.0, 209.0, 208.0, 206.0]\n",
            "Min num_ones: 206.0\n",
            "[213.0, 207.0, 198.0, 193.0, 190.0, 185.0]\n",
            "Min num_ones: 185.0\n",
            "[213.0, 207.0, 204.0, 202.0, 194.0, 189.0]\n",
            "Min num_ones: 189.0\n",
            "[213.0, 207.0, 198.0, 195.0, 194.0, 189.0]\n",
            "Min num_ones: 189.0\n",
            "[213.0, 207.0, 204.0, 202.0, 189.0]\n",
            "Min num_ones: 189.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = 5\n",
        "m = 5\n",
        "N = 2 ** w\n",
        "\n",
        "max_iter = 1000\n",
        "max_episodes = 10\n",
        "num_episodes = 0\n",
        "\n",
        "while (num_episodes < max_episodes):\n",
        "  # vec = [ i for i in range(N)]\n",
        "  # random.shuffle(vec)\n",
        "\n",
        "  num_ones = []\n",
        "  env = CauchyEnv(w, m, vec, num_ones)\n",
        "  tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "  time_step = tf_env.reset()\n",
        "  num_episodes += 1\n",
        "  num_ones.clear()\n",
        "\n",
        "  i = 0\n",
        "  for i in range(max_iter):\n",
        "    temperature = 100 - (i + 1.0)/max_iter*100 + 1\n",
        "    action = simulated_annealing_action(env._w, env._m, env._N, env._state, env._num_ones, temperature)\n",
        "    if action == -1:\n",
        "      break\n",
        "    time_step = tf_env.step(action)\n",
        "\n",
        "  if num_ones:\n",
        "    print(num_ones)\n",
        "    print(f'Min num_ones: {np.min(num_ones)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "EuiLw6wNkSxC",
        "outputId": "936fc654-05a9-48b1-fd38-b7f71fc6834d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[213.0, 213.0, 213.0, 207.0, 238.0, 228.0, 218.0, 228.0, 230.0, 244.0, 230.0, 230.0, 244.0, 244.0, 213.0, 213.0, 207.0, 207.0, 238.0, 238.0, 207.0, 238.0, 222.0, 222.0, 236.0, 236.0, 236.0, 213.0, 213.0, 207.0, 238.0, 238.0, 238.0, 238.0, 207.0, 238.0, 238.0, 207.0, 207.0, 238.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 238.0, 238.0, 238.0, 223.0, 223.0, 232.0, 213.0, 230.0, 231.0, 215.0, 215.0, 232.0, 237.0, 224.0, 224.0, 224.0, 227.0, 226.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 239.0, 238.0, 238.0, 234.0, 213.0, 213.0, 207.0, 213.0, 213.0, 207.0, 207.0, 239.0, 239.0, 241.0, 239.0, 241.0, 239.0, 213.0, 207.0, 207.0, 238.0, 228.0, 237.0, 219.0, 215.0, 232.0, 235.0, 232.0, 232.0, 224.0, 224.0, 224.0, 224.0, 214.0, 250.0, 226.0, 226.0, 239.0, 239.0, 226.0, 225.0, 225.0, 234.0, 225.0, 224.0, 214.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 224.0, 230.0, 220.0, 220.0, 225.0, 222.0, 229.0, 222.0, 222.0, 229.0, 222.0, 229.0, 222.0, 224.0, 214.0, 214.0, 213.0, 213.0, 220.0, 245.0, 211.0, 211.0, 224.0, 224.0, 242.0, 242.0, 224.0, 242.0, 242.0, 242.0, 224.0, 213.0, 213.0, 207.0, 207.0, 238.0, 239.0, 226.0, 239.0, 226.0, 239.0, 239.0, 239.0, 226.0, 238.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 217.0, 225.0, 225.0, 225.0, 229.0, 229.0, 229.0, 229.0, 215.0, 215.0, 229.0, 215.0, 229.0, 229.0, 215.0, 227.0, 227.0, 241.0, 227.0, 224.0, 224.0, 224.0, 214.0, 214.0, 236.0, 236.0, 218.0, 213.0, 213.0, 213.0, 218.0, 218.0, 213.0, 213.0, 213.0, 213.0, 218.0, 213.0, 225.0, 214.0, 201.0, 201.0, 201.0, 201.0, 222.0, 232.0, 232.0, 232.0, 232.0, 232.0, 210.0, 224.0, 216.0, 227.0, 222.0, 222.0, 241.0, 241.0, 222.0, 241.0, 222.0, 241.0, 241.0, 213.0, 207.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 224.0, 224.0, 224.0, 224.0, 221.0, 242.0, 244.0, 232.0, 225.0, 225.0, 225.0, 232.0, 232.0, 232.0, 232.0, 224.0, 204.0, 249.0, 234.0, 234.0, 234.0, 234.0, 222.0, 252.0, 222.0, 222.0, 252.0, 224.0, 209.0, 228.0, 228.0, 228.0, 228.0, 227.0, 232.0, 229.0, 222.0, 222.0, 226.0, 242.0, 224.0, 224.0, 224.0, 224.0, 224.0, 208.0, 208.0, 219.0, 219.0, 208.0, 208.0, 208.0, 219.0, 208.0, 208.0, 208.0, 234.0, 241.0, 227.0, 227.0, 227.0, 227.0, 227.0, 234.0, 234.0, 227.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 223.0, 241.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 227.0, 230.0, 230.0, 213.0, 207.0, 214.0, 203.0, 203.0, 203.0, 203.0, 203.0, 214.0, 200.0, 200.0, 200.0, 200.0, 218.0, 231.0, 218.0, 219.0, 219.0, 234.0, 234.0, 213.0, 214.0, 220.0, 227.0, 222.0, 218.0, 225.0, 231.0, 226.0, 226.0, 226.0, 224.0, 224.0, 224.0, 218.0, 214.0, 218.0, 218.0, 218.0, 214.0, 214.0, 226.0, 226.0, 222.0, 222.0, 226.0, 224.0, 214.0, 225.0, 223.0, 223.0, 225.0, 225.0, 218.0, 219.0, 219.0, 219.0, 218.0, 225.0, 242.0, 224.0, 224.0, 238.0, 239.0, 238.0, 211.0, 218.0, 218.0, 218.0, 235.0, 218.0, 218.0, 235.0, 228.0, 220.0, 228.0, 236.0, 218.0, 218.0, 218.0, 214.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 229.0, 220.0, 229.0, 229.0, 220.0, 229.0, 229.0, 229.0, 229.0, 213.0, 207.0, 238.0, 207.0, 238.0, 207.0, 207.0, 207.0, 238.0, 239.0, 239.0, 209.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 224.0, 240.0, 240.0, 206.0, 240.0, 206.0, 240.0, 240.0, 240.0, 240.0, 206.0, 206.0, 240.0, 231.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 210.0, 210.0, 232.0, 232.0, 232.0, 210.0, 232.0, 210.0, 210.0, 232.0, 232.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 229.0, 215.0, 229.0, 215.0, 229.0, 229.0, 229.0, 201.0, 217.0, 217.0, 234.0, 228.0, 228.0, 228.0, 228.0, 223.0, 247.0, 247.0, 213.0, 238.0, 207.0, 238.0, 238.0, 207.0, 238.0, 207.0, 207.0, 238.0, 207.0, 218.0, 218.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 223.0, 232.0, 222.0, 222.0, 213.0, 213.0, 228.0, 228.0, 216.0, 237.0, 216.0, 216.0, 237.0, 237.0, 235.0, 213.0, 213.0, 219.0, 219.0, 242.0, 242.0, 242.0, 242.0, 219.0, 219.0, 221.0, 224.0, 214.0, 225.0, 225.0, 221.0, 225.0, 225.0, 225.0, 221.0, 221.0, 225.0, 225.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 239.0, 222.0, 222.0, 222.0, 225.0, 225.0, 225.0, 228.0, 213.0, 207.0, 238.0, 238.0, 238.0, 231.0, 231.0, 227.0, 231.0, 227.0, 231.0, 223.0, 213.0, 207.0, 207.0, 209.0, 209.0, 222.0, 218.0, 222.0, 222.0, 222.0, 248.0, 236.0, 213.0, 207.0, 207.0, 238.0, 222.0, 231.0, 234.0, 247.0, 237.0, 237.0, 219.0, 226.0, 230.0, 224.0, 224.0, 214.0, 237.0, 226.0, 230.0, 217.0, 231.0, 231.0, 217.0, 217.0, 231.0, 217.0, 213.0, 213.0, 207.0, 207.0, 208.0, 212.0, 208.0, 208.0, 225.0, 225.0, 225.0, 217.0, 234.0, 224.0, 214.0, 224.0, 220.0, 220.0, 220.0, 236.0, 220.0, 220.0, 220.0, 214.0, 238.0, 213.0, 207.0, 207.0, 238.0, 220.0, 220.0, 228.0, 228.0, 228.0, 220.0, 220.0, 228.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 214.0, 214.0, 234.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 233.0, 229.0, 229.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 235.0, 235.0, 238.0, 203.0, 223.0, 223.0, 242.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 217.0, 217.0, 246.0, 214.0, 214.0, 237.0, 222.0, 222.0, 213.0, 207.0, 207.0, 207.0, 210.0, 218.0, 218.0, 231.0, 225.0, 231.0, 231.0, 225.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 239.0, 219.0, 219.0, 213.0, 207.0, 207.0, 220.0, 220.0, 222.0, 216.0, 222.0, 245.0, 245.0, 227.0, 227.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 207.0, 238.0, 207.0, 207.0, 218.0, 218.0, 218.0, 228.0, 228.0, 230.0, 230.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 221.0, 230.0, 230.0, 221.0, 221.0, 221.0, 230.0, 230.0, 226.0, 226.0, 213.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 210.0, 210.0, 232.0, 210.0, 232.0, 232.0, 210.0, 210.0, 232.0, 226.0, 226.0, 224.0, 224.0, 224.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 205.0, 205.0, 207.0, 207.0, 207.0, 217.0, 217.0, 217.0, 217.0, 246.0, 246.0, 225.0, 221.0, 221.0, 229.0, 229.0, 221.0, 229.0, 229.0, 221.0, 229.0, 229.0, 221.0, 224.0, 214.0, 213.0, 213.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 224.0, 224.0, 220.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 211.0, 207.0, 207.0, 207.0, 207.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 224.0, 222.0, 209.0, 219.0, 219.0, 210.0, 208.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 224.0, 224.0, 224.0, 222.0, 221.0]\n",
            "Min num_ones: 200.0\n",
            "[224.0, 223.0, 238.0, 238.0, 208.0, 216.0, 227.0, 227.0, 232.0, 227.0, 226.0, 229.0, 221.0, 221.0, 221.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 230.0, 230.0, 230.0, 221.0, 230.0, 224.0, 214.0, 214.0, 224.0, 222.0, 221.0, 222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 224.0, 224.0, 231.0, 231.0, 230.0, 245.0, 240.0, 226.0, 244.0, 244.0, 244.0, 213.0, 207.0, 207.0, 227.0, 227.0, 225.0, 227.0, 227.0, 225.0, 227.0, 220.0, 228.0, 224.0, 214.0, 214.0, 214.0, 209.0, 231.0, 238.0, 238.0, 238.0, 238.0, 238.0, 208.0, 208.0, 238.0, 238.0, 232.0, 229.0, 211.0, 229.0, 217.0, 210.0, 234.0, 221.0, 213.0, 205.0, 213.0, 205.0, 213.0, 213.0, 222.0, 222.0, 213.0, 222.0, 222.0, 213.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 220.0, 220.0, 220.0, 220.0, 213.0, 207.0, 238.0, 207.0, 207.0, 209.0, 209.0, 214.0, 209.0, 209.0, 214.0, 240.0, 213.0, 207.0, 247.0, 247.0, 247.0, 236.0, 249.0, 228.0, 215.0, 212.0, 217.0, 222.0, 224.0, 214.0, 218.0, 218.0, 213.0, 213.0, 213.0, 218.0, 213.0, 218.0, 213.0, 218.0, 218.0, 213.0, 213.0, 224.0, 214.0, 214.0, 218.0, 218.0, 218.0, 210.0, 233.0, 224.0, 233.0, 233.0, 233.0, 231.0, 226.0, 223.0, 223.0, 226.0, 224.0, 214.0, 224.0, 222.0, 222.0, 222.0, 222.0, 233.0, 233.0, 235.0, 229.0, 229.0, 224.0, 224.0, 229.0, 241.0, 242.0, 242.0, 228.0, 228.0, 228.0, 249.0, 200.0, 200.0, 249.0, 249.0, 230.0, 240.0, 240.0, 212.0, 212.0, 212.0, 217.0, 213.0, 213.0, 213.0, 213.0, 207.0, 238.0, 238.0, 207.0, 207.0, 238.0, 236.0, 220.0, 236.0, 236.0, 236.0, 213.0, 213.0, 207.0, 207.0, 238.0, 231.0, 231.0, 236.0, 236.0, 209.0, 236.0, 209.0, 201.0, 201.0, 201.0, 216.0, 216.0, 223.0, 233.0, 223.0, 223.0, 223.0, 223.0, 213.0, 213.0, 213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 234.0, 234.0, 227.0, 227.0, 234.0, 234.0, 224.0, 224.0, 224.0, 224.0, 214.0, 215.0, 233.0, 233.0, 233.0, 237.0, 237.0, 237.0, 237.0, 237.0, 235.0, 224.0, 214.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 210.0, 210.0, 210.0, 233.0, 228.0, 228.0, 228.0, 228.0, 229.0, 215.0, 234.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 244.0, 212.0, 212.0, 212.0, 221.0, 221.0, 221.0, 229.0, 221.0, 229.0, 221.0, 216.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 234.0, 235.0, 235.0, 239.0, 238.0, 232.0, 232.0, 234.0, 232.0, 234.0, 236.0, 234.0, 234.0, 224.0, 224.0, 224.0, 236.0, 234.0, 224.0, 224.0, 224.0, 225.0, 230.0, 230.0, 213.0, 207.0, 238.0, 246.0, 237.0, 222.0, 234.0, 234.0, 240.0, 216.0, 215.0, 215.0, 213.0, 207.0, 207.0, 198.0, 198.0, 198.0, 219.0, 219.0, 198.0, 198.0, 231.0, 233.0, 234.0, 226.0, 230.0, 223.0, 223.0, 223.0, 231.0, 250.0, 250.0, 230.0, 216.0, 216.0, 213.0, 227.0, 227.0, 216.0, 212.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 229.0, 224.0, 229.0, 229.0, 213.0, 213.0, 231.0, 231.0, 225.0, 233.0, 216.0, 234.0, 227.0, 231.0, 234.0, 224.0, 224.0, 214.0, 224.0, 207.0, 207.0, 207.0, 216.0, 216.0, 216.0, 216.0, 216.0, 249.0, 249.0, 233.0, 229.0, 223.0, 216.0, 223.0, 216.0, 235.0, 228.0, 228.0, 224.0, 224.0, 224.0, 224.0, 225.0, 224.0, 214.0, 214.0, 215.0, 224.0, 215.0, 224.0, 215.0, 213.0, 224.0, 215.0, 231.0, 231.0, 231.0, 198.0, 198.0, 198.0, 198.0, 241.0, 229.0, 216.0, 231.0, 231.0, 231.0, 232.0, 224.0, 214.0, 214.0, 214.0, 215.0, 215.0, 215.0, 215.0, 233.0, 233.0, 233.0, 215.0, 224.0, 214.0, 224.0, 224.0, 214.0, 226.0, 226.0, 238.0, 216.0, 237.0, 237.0, 215.0, 224.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 239.0, 247.0, 247.0, 232.0, 224.0, 214.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 232.0, 223.0, 224.0, 220.0, 220.0, 204.0, 204.0, 204.0, 220.0, 220.0, 204.0, 204.0, 220.0, 235.0, 235.0, 211.0, 213.0, 229.0, 225.0, 220.0, 220.0, 225.0, 225.0, 225.0, 217.0, 217.0, 217.0, 224.0, 214.0, 224.0, 224.0, 209.0, 209.0, 221.0, 230.0, 230.0, 230.0, 221.0, 222.0, 215.0, 215.0, 230.0, 211.0, 209.0, 235.0, 209.0, 234.0, 234.0, 223.0, 241.0, 235.0, 235.0, 235.0, 228.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 223.0, 223.0, 213.0, 213.0, 214.0, 214.0, 214.0, 239.0, 239.0, 216.0, 216.0, 239.0, 216.0, 213.0, 224.0, 224.0, 222.0, 222.0, 222.0, 222.0, 213.0, 222.0, 222.0, 222.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 217.0, 225.0, 225.0, 217.0, 225.0, 231.0, 222.0, 222.0, 224.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 224.0, 230.0, 228.0, 223.0, 225.0, 223.0, 225.0, 225.0, 223.0, 225.0, 225.0, 223.0, 225.0, 223.0, 213.0, 213.0, 207.0, 235.0, 226.0, 233.0, 226.0, 233.0, 228.0, 228.0, 230.0, 213.0, 221.0, 224.0, 214.0, 214.0, 224.0, 224.0, 231.0, 224.0, 224.0, 231.0, 220.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 226.0, 213.0, 213.0, 226.0, 213.0, 213.0, 226.0, 226.0, 213.0, 213.0, 226.0, 213.0, 213.0, 207.0, 207.0, 238.0, 207.0, 238.0, 231.0, 227.0, 236.0, 227.0, 227.0, 227.0, 224.0, 227.0, 227.0, 206.0, 227.0, 227.0, 227.0, 227.0, 215.0, 214.0, 214.0, 214.0, 214.0, 215.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 241.0, 214.0, 244.0, 244.0, 242.0, 213.0, 207.0, 207.0, 207.0, 234.0, 234.0, 234.0, 242.0, 242.0, 219.0, 230.0, 240.0, 224.0, 230.0, 221.0, 221.0, 230.0, 221.0, 221.0, 225.0, 227.0, 227.0, 231.0, 222.0, 222.0, 224.0, 226.0, 213.0, 226.0, 226.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 226.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 238.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 228.0, 232.0, 232.0, 232.0, 222.0, 213.0, 213.0, 222.0, 213.0, 224.0, 230.0, 230.0, 221.0, 221.0, 230.0, 230.0, 221.0, 230.0, 221.0, 221.0, 221.0, 223.0, 223.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 207.0, 238.0, 239.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 221.0, 218.0, 218.0, 218.0, 218.0, 210.0, 210.0, 207.0, 212.0, 212.0, 207.0, 207.0, 207.0, 207.0, 212.0, 207.0, 212.0, 207.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 207.0, 238.0, 238.0, 238.0, 224.0, 214.0, 214.0, 214.0, 214.0, 226.0, 226.0, 231.0, 231.0, 231.0, 223.0, 223.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 229.0, 218.0, 218.0, 218.0, 218.0, 230.0, 230.0, 235.0, 230.0, 230.0, 230.0, 230.0, 213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 214.0, 214.0, 214.0, 224.0, 212.0, 212.0, 212.0, 212.0, 226.0, 234.0, 234.0, 236.0, 236.0, 236.0, 231.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 221.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 217.0, 217.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0]\n",
            "Min num_ones: 198.0\n",
            "[224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 229.0, 220.0, 220.0, 220.0, 220.0, 213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 208.0, 208.0, 221.0, 232.0, 243.0, 232.0, 232.0, 216.0, 232.0, 216.0, 216.0, 232.0, 216.0, 216.0, 232.0, 232.0, 224.0, 214.0, 214.0, 222.0, 222.0, 222.0, 214.0, 238.0, 242.0, 238.0, 238.0, 238.0, 225.0, 214.0, 214.0, 223.0, 214.0, 223.0, 223.0, 214.0, 211.0, 224.0, 224.0, 219.0, 219.0, 224.0, 219.0, 222.0, 222.0, 224.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 220.0, 220.0, 229.0, 229.0, 213.0, 207.0, 238.0, 207.0, 238.0, 238.0, 207.0, 219.0, 242.0, 219.0, 219.0, 242.0, 224.0, 224.0, 214.0, 214.0, 217.0, 223.0, 223.0, 217.0, 217.0, 223.0, 223.0, 223.0, 223.0, 213.0, 207.0, 238.0, 207.0, 207.0, 238.0, 207.0, 218.0, 218.0, 227.0, 218.0, 218.0, 213.0, 213.0, 213.0, 213.0, 207.0, 209.0, 209.0, 214.0, 234.0, 213.0, 228.0, 213.0, 213.0, 225.0, 225.0, 213.0, 213.0, 207.0, 207.0, 207.0, 239.0, 238.0, 238.0, 238.0, 239.0, 238.0, 238.0, 239.0, 213.0, 213.0, 226.0, 226.0, 207.0, 225.0, 225.0, 226.0, 225.0, 225.0, 226.0, 225.0, 225.0, 225.0, 226.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 209.0, 223.0, 209.0, 223.0, 223.0, 223.0, 225.0, 221.0, 239.0, 229.0, 220.0, 224.0, 224.0, 220.0, 216.0, 216.0, 216.0, 216.0, 220.0, 216.0, 220.0, 220.0, 216.0, 220.0, 235.0, 224.0, 214.0, 224.0, 227.0, 249.0, 218.0, 210.0, 241.0, 225.0, 241.0, 241.0, 234.0, 222.0, 222.0, 234.0, 216.0, 234.0, 225.0, 228.0, 225.0, 205.0, 205.0, 219.0, 244.0, 233.0, 233.0, 244.0, 239.0, 239.0, 239.0, 230.0, 224.0, 210.0, 210.0, 210.0, 210.0, 232.0, 232.0, 210.0, 232.0, 210.0, 210.0, 232.0, 224.0, 214.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 205.0, 228.0, 205.0, 205.0, 228.0, 205.0, 205.0, 205.0, 228.0, 228.0, 213.0, 213.0, 207.0, 238.0, 239.0, 239.0, 226.0, 239.0, 239.0, 239.0, 226.0, 226.0, 226.0, 224.0, 214.0, 224.0, 231.0, 214.0, 214.0, 231.0, 231.0, 214.0, 231.0, 231.0, 240.0, 225.0, 230.0, 227.0, 242.0, 225.0, 225.0, 225.0, 237.0, 237.0, 226.0, 224.0, 224.0, 233.0, 233.0, 224.0, 224.0, 242.0, 228.0, 228.0, 228.0, 222.0, 222.0, 225.0, 225.0, 225.0, 234.0, 209.0, 215.0, 215.0, 215.0, 219.0, 219.0, 208.0, 238.0, 234.0, 226.0, 225.0, 222.0, 232.0, 232.0, 222.0, 222.0, 222.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 232.0, 218.0, 218.0, 232.0, 218.0, 213.0, 207.0, 207.0, 238.0, 238.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 213.0, 213.0, 203.0, 214.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 207.0, 239.0, 213.0, 209.0, 222.0, 222.0, 222.0, 222.0, 209.0, 222.0, 209.0, 222.0, 241.0, 229.0, 224.0, 240.0, 206.0, 206.0, 206.0, 206.0, 206.0, 240.0, 240.0, 206.0, 240.0, 214.0, 207.0, 224.0, 234.0, 249.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 248.0, 248.0, 213.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 221.0, 221.0, 221.0, 228.0, 224.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 238.0, 213.0, 207.0, 238.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 220.0, 230.0, 230.0, 224.0, 224.0, 224.0, 240.0, 206.0, 206.0, 206.0, 216.0, 227.0, 222.0, 222.0, 227.0, 226.0, 234.0, 247.0, 222.0, 223.0, 214.0, 214.0, 214.0, 229.0, 229.0, 229.0, 229.0, 221.0, 221.0, 229.0, 226.0, 224.0, 224.0, 214.0, 214.0, 224.0, 229.0, 238.0, 203.0, 223.0, 203.0, 203.0, 223.0, 223.0, 223.0, 223.0, 223.0, 203.0, 203.0, 213.0, 213.0, 207.0, 207.0, 207.0, 220.0, 220.0, 211.0, 233.0, 233.0, 233.0, 233.0, 199.0, 240.0, 231.0, 231.0, 231.0, 231.0, 231.0, 229.0, 231.0, 231.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 207.0, 238.0, 213.0, 213.0, 213.0, 207.0, 207.0, 241.0, 241.0, 241.0, 228.0, 241.0, 241.0, 228.0, 228.0, 241.0, 213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 221.0, 228.0, 221.0, 232.0, 230.0, 213.0, 207.0, 207.0, 207.0, 205.0, 205.0, 205.0, 213.0, 205.0, 205.0, 205.0, 213.0, 213.0, 205.0, 213.0, 224.0, 222.0, 241.0, 222.0, 222.0, 222.0, 241.0, 222.0, 222.0, 222.0, 222.0, 224.0, 224.0, 240.0, 240.0, 221.0, 221.0, 222.0, 221.0, 222.0, 222.0, 222.0, 221.0, 221.0, 216.0, 216.0, 224.0, 216.0, 224.0, 216.0, 216.0, 224.0, 224.0, 224.0, 226.0, 219.0, 217.0, 217.0, 210.0, 226.0, 226.0, 231.0, 231.0, 217.0, 217.0, 217.0, 231.0, 217.0, 217.0, 213.0, 213.0, 207.0, 207.0, 238.0, 227.0, 234.0, 234.0, 234.0, 234.0, 234.0, 227.0, 227.0, 224.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 234.0, 234.0, 220.0, 216.0, 220.0, 220.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 224.0, 224.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 238.0, 238.0, 238.0, 207.0, 207.0, 207.0, 232.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 221.0, 221.0, 221.0, 214.0, 214.0, 226.0, 224.0, 217.0, 219.0, 217.0, 219.0, 219.0, 217.0, 217.0, 217.0, 216.0, 216.0, 217.0, 219.0, 221.0, 221.0, 219.0, 238.0, 226.0, 226.0, 238.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 224.0, 214.0, 215.0, 215.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 215.0, 243.0, 210.0, 232.0, 207.0, 218.0, 218.0, 234.0, 234.0, 221.0, 225.0, 225.0, 227.0, 227.0, 227.0, 213.0, 213.0, 213.0, 207.0, 204.0, 212.0, 212.0, 204.0, 204.0, 212.0, 212.0, 212.0, 212.0, 204.0, 219.0, 224.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 222.0, 209.0, 209.0, 210.0, 210.0, 208.0, 208.0, 208.0, 208.0, 241.0, 241.0, 208.0, 223.0, 223.0, 227.0, 227.0, 224.0, 229.0, 234.0, 233.0, 233.0, 233.0, 245.0, 245.0, 224.0, 228.0, 225.0, 213.0, 230.0, 231.0, 241.0, 241.0, 241.0, 236.0, 236.0, 232.0, 232.0, 225.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 229.0, 224.0, 214.0, 214.0, 230.0, 207.0, 221.0, 226.0, 226.0, 216.0, 216.0, 219.0, 218.0, 227.0, 227.0, 218.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 224.0, 211.0, 211.0, 206.0, 206.0, 207.0, 219.0, 219.0, 219.0, 207.0, 207.0, 207.0, 214.0, 214.0, 236.0, 228.0, 223.0, 223.0, 223.0, 223.0, 223.0, 217.0, 236.0, 233.0, 227.0, 227.0, 233.0, 245.0, 232.0, 232.0, 232.0, 232.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 224.0, 214.0, 214.0, 214.0, 219.0, 219.0, 217.0, 217.0, 217.0, 213.0, 213.0, 213.0, 213.0, 213.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 224.0, 214.0, 224.0, 220.0, 220.0, 220.0, 220.0, 220.0, 236.0, 236.0, 233.0, 233.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 216.0, 216.0, 216.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 224.0, 214.0, 214.0, 214.0, 214.0, 216.0, 216.0, 216.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0]\n",
            "Min num_ones: 199.0\n",
            "[242.0, 231.0, 218.0, 210.0, 238.0, 238.0, 238.0, 238.0, 225.0, 225.0, 238.0, 238.0, 238.0, 238.0, 213.0, 213.0, 207.0, 241.0, 241.0, 241.0, 241.0, 228.0, 214.0, 243.0, 243.0, 226.0, 226.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 220.0, 220.0, 236.0, 236.0, 224.0, 233.0, 215.0, 233.0, 215.0, 233.0, 215.0, 233.0, 217.0, 221.0, 217.0, 217.0, 221.0, 228.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 232.0, 212.0, 212.0, 209.0, 212.0, 224.0, 221.0, 249.0, 232.0, 232.0, 221.0, 219.0, 237.0, 223.0, 232.0, 222.0, 222.0, 222.0, 222.0, 222.0, 209.0, 209.0, 209.0, 209.0, 222.0, 222.0, 222.0, 222.0, 231.0, 224.0, 223.0, 213.0, 213.0, 207.0, 238.0, 238.0, 207.0, 207.0, 238.0, 238.0, 234.0, 234.0, 234.0, 234.0, 213.0, 207.0, 207.0, 238.0, 207.0, 208.0, 212.0, 208.0, 212.0, 212.0, 212.0, 208.0, 224.0, 231.0, 244.0, 244.0, 244.0, 244.0, 236.0, 220.0, 218.0, 233.0, 220.0, 220.0, 220.0, 220.0, 233.0, 220.0, 225.0, 225.0, 233.0, 224.0, 222.0, 222.0, 221.0, 221.0, 222.0, 227.0, 244.0, 238.0, 238.0, 211.0, 211.0, 232.0, 244.0, 244.0, 232.0, 232.0, 244.0, 244.0, 244.0, 232.0, 223.0, 232.0, 238.0, 221.0, 225.0, 225.0, 225.0, 244.0, 244.0, 220.0, 220.0, 231.0, 231.0, 225.0, 225.0, 231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 238.0, 238.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 238.0, 227.0, 227.0, 227.0, 213.0, 213.0, 213.0, 213.0, 213.0, 223.0, 223.0, 221.0, 221.0, 221.0, 221.0, 230.0, 234.0, 234.0, 234.0, 234.0, 223.0, 223.0, 223.0, 223.0, 226.0, 223.0, 223.0, 226.0, 223.0, 229.0, 236.0, 213.0, 213.0, 207.0, 238.0, 238.0, 229.0, 224.0, 231.0, 231.0, 230.0, 231.0, 235.0, 235.0, 224.0, 228.0, 228.0, 228.0, 242.0, 238.0, 231.0, 234.0, 231.0, 234.0, 234.0, 213.0, 207.0, 207.0, 238.0, 238.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 238.0, 213.0, 212.0, 204.0, 204.0, 212.0, 212.0, 212.0, 204.0, 219.0, 222.0, 219.0, 219.0, 219.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 224.0, 216.0, 231.0, 224.0, 214.0, 214.0, 235.0, 226.0, 226.0, 220.0, 229.0, 221.0, 229.0, 221.0, 235.0, 218.0, 224.0, 224.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 224.0, 213.0, 207.0, 207.0, 226.0, 226.0, 226.0, 226.0, 226.0, 247.0, 219.0, 226.0, 219.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 233.0, 233.0, 234.0, 234.0, 226.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 215.0, 225.0, 225.0, 218.0, 218.0, 210.0, 210.0, 213.0, 213.0, 220.0, 220.0, 220.0, 220.0, 227.0, 227.0, 230.0, 213.0, 207.0, 207.0, 238.0, 238.0, 207.0, 238.0, 238.0, 238.0, 238.0, 207.0, 207.0, 224.0, 224.0, 214.0, 214.0, 218.0, 218.0, 210.0, 228.0, 228.0, 228.0, 232.0, 232.0, 232.0, 232.0, 232.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 232.0, 201.0, 201.0, 201.0, 232.0, 213.0, 227.0, 218.0, 228.0, 218.0, 218.0, 228.0, 218.0, 228.0, 218.0, 228.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 214.0, 207.0, 241.0, 241.0, 231.0, 223.0, 223.0, 223.0, 231.0, 231.0, 223.0, 231.0, 213.0, 210.0, 210.0, 233.0, 233.0, 233.0, 233.0, 218.0, 218.0, 231.0, 215.0, 231.0, 225.0, 227.0, 227.0, 231.0, 220.0, 238.0, 220.0, 220.0, 238.0, 220.0, 220.0, 220.0, 218.0, 218.0, 217.0, 217.0, 217.0, 218.0, 225.0, 225.0, 226.0, 239.0, 231.0, 236.0, 236.0, 213.0, 213.0, 207.0, 238.0, 207.0, 238.0, 207.0, 238.0, 238.0, 207.0, 207.0, 218.0, 227.0, 224.0, 224.0, 231.0, 228.0, 215.0, 237.0, 237.0, 232.0, 237.0, 237.0, 237.0, 232.0, 232.0, 232.0, 232.0, 213.0, 207.0, 214.0, 225.0, 233.0, 250.0, 207.0, 207.0, 207.0, 207.0, 220.0, 220.0, 224.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 221.0, 226.0, 223.0, 223.0, 224.0, 224.0, 224.0, 222.0, 235.0, 216.0, 223.0, 247.0, 229.0, 247.0, 231.0, 225.0, 231.0, 225.0, 231.0, 225.0, 224.0, 231.0, 231.0, 231.0, 230.0, 231.0, 234.0, 220.0, 220.0, 220.0, 234.0, 234.0, 234.0, 220.0, 234.0, 220.0, 220.0, 220.0, 213.0, 213.0, 207.0, 238.0, 238.0, 207.0, 238.0, 207.0, 238.0, 207.0, 207.0, 205.0, 220.0, 228.0, 212.0, 212.0, 212.0, 222.0, 212.0, 212.0, 212.0, 212.0, 221.0, 231.0, 231.0, 231.0, 219.0, 229.0, 230.0, 229.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 230.0, 213.0, 207.0, 207.0, 207.0, 239.0, 242.0, 239.0, 242.0, 239.0, 242.0, 239.0, 216.0, 213.0, 207.0, 238.0, 207.0, 244.0, 244.0, 244.0, 230.0, 230.0, 230.0, 230.0, 230.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 207.0, 238.0, 238.0, 227.0, 205.0, 213.0, 213.0, 205.0, 213.0, 213.0, 205.0, 205.0, 205.0, 215.0, 206.0, 224.0, 224.0, 214.0, 214.0, 224.0, 227.0, 227.0, 216.0, 227.0, 227.0, 236.0, 236.0, 236.0, 213.0, 207.0, 222.0, 233.0, 233.0, 226.0, 226.0, 226.0, 218.0, 201.0, 201.0, 201.0, 201.0, 201.0, 218.0, 201.0, 201.0, 218.0, 201.0, 201.0, 213.0, 227.0, 227.0, 227.0, 231.0, 231.0, 232.0, 232.0, 228.0, 221.0, 232.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 235.0, 225.0, 220.0, 238.0, 238.0, 219.0, 219.0, 219.0, 219.0, 219.0, 221.0, 219.0, 221.0, 219.0, 233.0, 229.0, 213.0, 228.0, 223.0, 223.0, 232.0, 232.0, 223.0, 223.0, 223.0, 238.0, 235.0, 213.0, 213.0, 207.0, 213.0, 213.0, 213.0, 232.0, 230.0, 226.0, 236.0, 236.0, 247.0, 221.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 218.0, 228.0, 229.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 212.0, 218.0, 218.0, 212.0, 229.0, 226.0, 221.0, 221.0, 226.0, 226.0, 226.0, 213.0, 213.0, 213.0, 228.0, 228.0, 228.0, 228.0, 228.0, 231.0, 232.0, 231.0, 224.0, 221.0, 221.0, 221.0, 208.0, 212.0, 218.0, 222.0, 231.0, 225.0, 233.0, 233.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 219.0, 217.0, 217.0, 237.0, 230.0, 244.0, 237.0, 228.0, 231.0, 231.0, 224.0, 214.0, 224.0, 214.0, 217.0, 217.0, 217.0, 221.0, 217.0, 217.0, 217.0, 228.0, 224.0, 213.0, 218.0, 218.0, 219.0, 218.0, 219.0, 218.0, 219.0, 219.0, 219.0, 218.0, 224.0, 214.0, 224.0, 214.0, 224.0, 214.0, 217.0, 217.0, 217.0, 217.0, 223.0, 223.0, 224.0, 220.0, 216.0, 220.0, 216.0, 216.0, 216.0, 207.0, 207.0, 207.0, 207.0, 203.0, 203.0, 222.0, 238.0, 238.0, 222.0, 238.0, 222.0, 222.0, 238.0, 238.0, 223.0, 215.0, 215.0, 215.0, 215.0, 215.0, 224.0, 224.0, 222.0, 224.0, 222.0, 224.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 210.0, 212.0, 212.0, 210.0, 212.0, 212.0, 212.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 198.0, 198.0, 198.0, 198.0, 219.0, 219.0, 198.0, 198.0, 198.0, 198.0, 198.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 205.0, 205.0, 213.0, 205.0, 213.0, 205.0, 205.0, 205.0, 205.0, 205.0, 213.0, 224.0, 224.0, 207.0, 209.0, 209.0, 209.0, 209.0, 209.0, 240.0, 240.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 226.0, 207.0, 207.0, 213.0, 207.0, 210.0, 210.0, 212.0, 210.0, 210.0, 210.0, 210.0, 212.0, 212.0, 210.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 215.0, 215.0, 224.0, 215.0, 215.0, 215.0, 224.0, 224.0, 224.0, 224.0, 224.0, 222.0, 224.0, 216.0, 216.0, 216.0, 216.0, 216.0, 213.0, 213.0, 213.0, 212.0, 212.0, 213.0, 212.0, 212.0, 213.0, 212.0, 212.0, 208.0, 208.0, 208.0, 210.0]\n",
            "Min num_ones: 198.0\n",
            "[213.0, 213.0, 213.0, 237.0, 237.0, 237.0, 226.0, 230.0, 230.0, 226.0, 230.0, 213.0, 207.0, 222.0, 214.0, 222.0, 214.0, 214.0, 214.0, 214.0, 222.0, 214.0, 214.0, 224.0, 231.0, 214.0, 208.0, 208.0, 213.0, 213.0, 232.0, 226.0, 226.0, 234.0, 234.0, 234.0, 239.0, 213.0, 213.0, 213.0, 213.0, 207.0, 210.0, 212.0, 210.0, 210.0, 212.0, 210.0, 210.0, 222.0, 213.0, 222.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 222.0, 213.0, 221.0, 221.0, 234.0, 221.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 235.0, 239.0, 239.0, 222.0, 238.0, 229.0, 240.0, 216.0, 216.0, 224.0, 231.0, 231.0, 231.0, 231.0, 232.0, 232.0, 232.0, 218.0, 218.0, 228.0, 228.0, 218.0, 228.0, 218.0, 228.0, 228.0, 218.0, 228.0, 224.0, 224.0, 231.0, 232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 232.0, 231.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 224.0, 212.0, 212.0, 219.0, 212.0, 212.0, 212.0, 212.0, 212.0, 219.0, 229.0, 238.0, 224.0, 224.0, 240.0, 206.0, 206.0, 240.0, 231.0, 214.0, 210.0, 210.0, 244.0, 216.0, 219.0, 219.0, 213.0, 213.0, 207.0, 207.0, 246.0, 224.0, 224.0, 217.0, 219.0, 219.0, 217.0, 227.0, 227.0, 234.0, 219.0, 219.0, 219.0, 242.0, 242.0, 242.0, 223.0, 205.0, 205.0, 205.0, 205.0, 220.0, 220.0, 220.0, 220.0, 226.0, 205.0, 226.0, 224.0, 214.0, 224.0, 224.0, 224.0, 228.0, 242.0, 234.0, 225.0, 219.0, 219.0, 240.0, 238.0, 230.0, 232.0, 240.0, 240.0, 240.0, 242.0, 227.0, 244.0, 244.0, 236.0, 219.0, 211.0, 215.0, 215.0, 221.0, 222.0, 226.0, 226.0, 243.0, 243.0, 221.0, 221.0, 218.0, 218.0, 245.0, 244.0, 244.0, 244.0, 240.0, 240.0, 240.0, 240.0, 240.0, 214.0, 210.0, 210.0, 218.0, 228.0, 228.0, 218.0, 212.0, 212.0, 212.0, 244.0, 244.0, 224.0, 214.0, 214.0, 214.0, 214.0, 233.0, 234.0, 232.0, 222.0, 231.0, 226.0, 231.0, 224.0, 214.0, 224.0, 224.0, 218.0, 218.0, 212.0, 213.0, 213.0, 213.0, 208.0, 213.0, 225.0, 238.0, 225.0, 225.0, 238.0, 242.0, 242.0, 242.0, 238.0, 213.0, 213.0, 207.0, 207.0, 210.0, 210.0, 212.0, 210.0, 210.0, 210.0, 217.0, 231.0, 217.0, 224.0, 224.0, 210.0, 230.0, 230.0, 210.0, 236.0, 236.0, 231.0, 218.0, 218.0, 229.0, 227.0, 224.0, 214.0, 214.0, 214.0, 224.0, 213.0, 218.0, 213.0, 217.0, 217.0, 219.0, 217.0, 217.0, 221.0, 244.0, 220.0, 224.0, 214.0, 224.0, 214.0, 237.0, 226.0, 226.0, 226.0, 226.0, 237.0, 234.0, 234.0, 224.0, 214.0, 214.0, 224.0, 224.0, 229.0, 213.0, 218.0, 233.0, 233.0, 238.0, 238.0, 247.0, 247.0, 247.0, 247.0, 226.0, 224.0, 224.0, 214.0, 224.0, 223.0, 223.0, 225.0, 225.0, 225.0, 217.0, 217.0, 217.0, 217.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 221.0, 221.0, 221.0, 221.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 229.0, 227.0, 227.0, 235.0, 222.0, 234.0, 224.0, 224.0, 214.0, 224.0, 222.0, 227.0, 217.0, 227.0, 227.0, 217.0, 217.0, 230.0, 212.0, 231.0, 212.0, 223.0, 223.0, 228.0, 223.0, 228.0, 240.0, 232.0, 240.0, 224.0, 228.0, 242.0, 228.0, 242.0, 226.0, 233.0, 229.0, 237.0, 226.0, 233.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 223.0, 223.0, 225.0, 225.0, 225.0, 225.0, 230.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 223.0, 232.0, 232.0, 223.0, 232.0, 232.0, 223.0, 204.0, 206.0, 204.0, 206.0, 230.0, 230.0, 230.0, 201.0, 215.0, 208.0, 208.0, 208.0, 224.0, 235.0, 224.0, 224.0, 235.0, 224.0, 213.0, 213.0, 227.0, 227.0, 223.0, 223.0, 223.0, 237.0, 232.0, 232.0, 229.0, 213.0, 231.0, 220.0, 220.0, 208.0, 208.0, 208.0, 230.0, 208.0, 218.0, 207.0, 207.0, 229.0, 233.0, 229.0, 229.0, 229.0, 229.0, 229.0, 233.0, 229.0, 213.0, 207.0, 205.0, 207.0, 238.0, 207.0, 207.0, 226.0, 226.0, 226.0, 228.0, 228.0, 228.0, 224.0, 221.0, 242.0, 221.0, 242.0, 221.0, 242.0, 242.0, 242.0, 221.0, 221.0, 237.0, 224.0, 223.0, 209.0, 209.0, 223.0, 209.0, 223.0, 223.0, 223.0, 223.0, 209.0, 209.0, 236.0, 224.0, 214.0, 214.0, 250.0, 250.0, 250.0, 233.0, 231.0, 229.0, 218.0, 218.0, 218.0, 213.0, 213.0, 207.0, 238.0, 238.0, 207.0, 238.0, 238.0, 241.0, 231.0, 231.0, 241.0, 241.0, 213.0, 207.0, 207.0, 238.0, 238.0, 238.0, 238.0, 207.0, 207.0, 243.0, 243.0, 243.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 227.0, 223.0, 227.0, 233.0, 213.0, 213.0, 207.0, 222.0, 222.0, 222.0, 231.0, 202.0, 202.0, 219.0, 222.0, 219.0, 240.0, 229.0, 233.0, 229.0, 229.0, 229.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 209.0, 209.0, 209.0, 209.0, 209.0, 243.0, 209.0, 243.0, 221.0, 232.0, 239.0, 213.0, 218.0, 219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 219.0, 218.0, 213.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 238.0, 238.0, 207.0, 207.0, 238.0, 244.0, 223.0, 223.0, 225.0, 235.0, 235.0, 235.0, 235.0, 225.0, 229.0, 229.0, 229.0, 224.0, 224.0, 218.0, 228.0, 227.0, 227.0, 218.0, 219.0, 231.0, 240.0, 240.0, 240.0, 240.0, 213.0, 207.0, 238.0, 238.0, 207.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 238.0, 213.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 226.0, 218.0, 226.0, 240.0, 240.0, 226.0, 224.0, 224.0, 224.0, 214.0, 217.0, 221.0, 221.0, 238.0, 221.0, 221.0, 221.0, 238.0, 221.0, 238.0, 213.0, 205.0, 205.0, 205.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 205.0, 207.0, 224.0, 214.0, 214.0, 232.0, 218.0, 218.0, 218.0, 241.0, 241.0, 212.0, 215.0, 233.0, 233.0, 233.0, 233.0, 233.0, 237.0, 237.0, 233.0, 237.0, 213.0, 207.0, 207.0, 238.0, 238.0, 222.0, 222.0, 239.0, 222.0, 238.0, 235.0, 235.0, 213.0, 223.0, 218.0, 218.0, 228.0, 236.0, 231.0, 214.0, 214.0, 214.0, 231.0, 224.0, 214.0, 214.0, 224.0, 224.0, 210.0, 210.0, 224.0, 224.0, 230.0, 233.0, 233.0, 230.0, 231.0, 231.0, 231.0, 213.0, 221.0, 229.0, 229.0, 221.0, 221.0, 221.0, 233.0, 232.0, 221.0, 221.0, 213.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 207.0, 208.0, 205.0, 205.0, 205.0, 213.0, 222.0, 222.0, 222.0, 213.0, 213.0, 213.0, 213.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 217.0, 217.0, 223.0, 243.0, 243.0, 243.0, 243.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 215.0, 215.0, 215.0, 215.0, 215.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 234.0, 234.0, 234.0, 237.0, 224.0, 227.0, 214.0, 223.0, 214.0, 223.0, 214.0, 214.0, 223.0, 214.0, 214.0, 223.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 221.0, 221.0, 221.0, 221.0, 221.0, 229.0, 229.0, 224.0, 224.0, 214.0, 235.0, 235.0, 222.0, 235.0, 222.0, 224.0, 224.0, 238.0, 224.0, 224.0, 224.0, 220.0, 220.0, 232.0, 232.0, 228.0, 216.0, 216.0, 216.0, 216.0, 216.0, 228.0, 228.0, 228.0, 228.0, 228.0, 237.0, 213.0, 218.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 216.0, 216.0, 216.0, 224.0, 214.0, 214.0, 209.0, 209.0, 209.0, 226.0, 226.0, 223.0, 223.0, 223.0, 223.0, 225.0, 223.0, 224.0, 224.0, 214.0, 214.0, 218.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 228.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 198.0, 198.0, 205.0, 205.0, 205.0, 205.0, 207.0, 207.0, 207.0, 205.0, 205.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0]\n",
            "Min num_ones: 198.0\n",
            "[213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 238.0, 238.0, 213.0, 224.0, 224.0, 239.0, 213.0, 207.0, 227.0, 231.0, 227.0, 227.0, 221.0, 230.0, 230.0, 216.0, 216.0, 230.0, 213.0, 213.0, 213.0, 235.0, 224.0, 224.0, 220.0, 238.0, 220.0, 220.0, 228.0, 224.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 228.0, 242.0, 228.0, 242.0, 228.0, 221.0, 218.0, 224.0, 224.0, 224.0, 224.0, 222.0, 222.0, 209.0, 222.0, 222.0, 209.0, 222.0, 209.0, 209.0, 222.0, 221.0, 238.0, 238.0, 232.0, 236.0, 236.0, 222.0, 222.0, 222.0, 222.0, 230.0, 229.0, 229.0, 213.0, 229.0, 229.0, 213.0, 224.0, 224.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 231.0, 211.0, 224.0, 214.0, 224.0, 213.0, 213.0, 224.0, 234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 224.0, 224.0, 213.0, 215.0, 211.0, 224.0, 219.0, 237.0, 241.0, 237.0, 241.0, 237.0, 237.0, 241.0, 237.0, 223.0, 232.0, 221.0, 221.0, 232.0, 237.0, 237.0, 237.0, 237.0, 227.0, 214.0, 225.0, 214.0, 214.0, 225.0, 214.0, 214.0, 214.0, 228.0, 226.0, 238.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 231.0, 231.0, 220.0, 242.0, 231.0, 220.0, 224.0, 224.0, 224.0, 240.0, 224.0, 240.0, 230.0, 230.0, 232.0, 232.0, 224.0, 224.0, 214.0, 228.0, 230.0, 230.0, 228.0, 228.0, 239.0, 239.0, 228.0, 228.0, 228.0, 213.0, 223.0, 223.0, 232.0, 232.0, 232.0, 245.0, 224.0, 224.0, 224.0, 245.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 213.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 238.0, 238.0, 207.0, 207.0, 219.0, 219.0, 237.0, 229.0, 229.0, 246.0, 246.0, 222.0, 222.0, 242.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 234.0, 225.0, 225.0, 234.0, 237.0, 224.0, 224.0, 214.0, 236.0, 236.0, 230.0, 230.0, 230.0, 233.0, 230.0, 219.0, 219.0, 219.0, 224.0, 214.0, 214.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 229.0, 213.0, 207.0, 207.0, 207.0, 238.0, 238.0, 207.0, 207.0, 228.0, 229.0, 221.0, 221.0, 228.0, 223.0, 223.0, 234.0, 213.0, 213.0, 233.0, 233.0, 233.0, 235.0, 233.0, 235.0, 235.0, 233.0, 235.0, 224.0, 224.0, 214.0, 215.0, 215.0, 219.0, 219.0, 215.0, 215.0, 219.0, 219.0, 215.0, 215.0, 213.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 238.0, 234.0, 234.0, 234.0, 247.0, 213.0, 207.0, 238.0, 231.0, 227.0, 227.0, 227.0, 214.0, 224.0, 236.0, 218.0, 236.0, 224.0, 230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 224.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 213.0, 207.0, 238.0, 207.0, 238.0, 240.0, 221.0, 240.0, 221.0, 240.0, 240.0, 221.0, 224.0, 224.0, 209.0, 243.0, 209.0, 210.0, 205.0, 210.0, 210.0, 210.0, 210.0, 211.0, 211.0, 231.0, 213.0, 225.0, 227.0, 224.0, 224.0, 224.0, 224.0, 230.0, 230.0, 230.0, 230.0, 219.0, 216.0, 216.0, 234.0, 228.0, 211.0, 211.0, 228.0, 211.0, 211.0, 211.0, 211.0, 228.0, 237.0, 237.0, 237.0, 243.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 224.0, 220.0, 220.0, 238.0, 238.0, 220.0, 220.0, 220.0, 220.0, 223.0, 223.0, 226.0, 213.0, 213.0, 207.0, 207.0, 238.0, 207.0, 214.0, 214.0, 225.0, 225.0, 217.0, 217.0, 217.0, 224.0, 224.0, 214.0, 224.0, 224.0, 224.0, 230.0, 230.0, 222.0, 222.0, 221.0, 222.0, 221.0, 213.0, 213.0, 213.0, 213.0, 207.0, 238.0, 238.0, 238.0, 213.0, 222.0, 213.0, 222.0, 222.0, 219.0, 214.0, 224.0, 214.0, 224.0, 230.0, 229.0, 234.0, 237.0, 237.0, 235.0, 235.0, 218.0, 218.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 219.0, 222.0, 219.0, 233.0, 214.0, 221.0, 221.0, 217.0, 217.0, 217.0, 213.0, 213.0, 250.0, 226.0, 226.0, 239.0, 239.0, 239.0, 226.0, 243.0, 243.0, 213.0, 209.0, 209.0, 222.0, 222.0, 209.0, 209.0, 209.0, 222.0, 209.0, 222.0, 222.0, 225.0, 214.0, 220.0, 214.0, 220.0, 220.0, 214.0, 214.0, 220.0, 220.0, 214.0, 214.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 235.0, 222.0, 235.0, 222.0, 222.0, 222.0, 222.0, 224.0, 234.0, 234.0, 234.0, 234.0, 249.0, 234.0, 249.0, 249.0, 234.0, 233.0, 230.0, 229.0, 214.0, 214.0, 224.0, 233.0, 234.0, 234.0, 237.0, 241.0, 233.0, 233.0, 241.0, 224.0, 218.0, 212.0, 218.0, 212.0, 212.0, 218.0, 218.0, 229.0, 229.0, 221.0, 221.0, 229.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 241.0, 241.0, 241.0, 228.0, 228.0, 228.0, 228.0, 228.0, 224.0, 214.0, 214.0, 214.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 229.0, 213.0, 213.0, 229.0, 213.0, 216.0, 216.0, 229.0, 229.0, 229.0, 216.0, 231.0, 224.0, 214.0, 214.0, 224.0, 214.0, 224.0, 214.0, 224.0, 221.0, 240.0, 221.0, 221.0, 224.0, 224.0, 227.0, 227.0, 231.0, 231.0, 239.0, 231.0, 239.0, 231.0, 220.0, 238.0, 220.0, 238.0, 220.0, 238.0, 220.0, 220.0, 220.0, 220.0, 220.0, 213.0, 213.0, 207.0, 241.0, 241.0, 241.0, 241.0, 241.0, 236.0, 236.0, 236.0, 225.0, 225.0, 213.0, 207.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 235.0, 238.0, 238.0, 235.0, 213.0, 213.0, 213.0, 207.0, 223.0, 245.0, 245.0, 228.0, 245.0, 228.0, 245.0, 228.0, 228.0, 245.0, 213.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 222.0, 213.0, 222.0, 222.0, 222.0, 224.0, 214.0, 237.0, 228.0, 234.0, 242.0, 234.0, 234.0, 242.0, 234.0, 228.0, 235.0, 213.0, 228.0, 228.0, 221.0, 235.0, 235.0, 235.0, 225.0, 235.0, 231.0, 247.0, 213.0, 213.0, 213.0, 207.0, 238.0, 207.0, 220.0, 233.0, 233.0, 199.0, 199.0, 233.0, 233.0, 199.0, 199.0, 199.0, 199.0, 233.0, 233.0, 233.0, 213.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 207.0, 223.0, 207.0, 238.0, 207.0, 229.0, 233.0, 226.0, 226.0, 233.0, 232.0, 228.0, 228.0, 232.0, 229.0, 213.0, 217.0, 217.0, 217.0, 217.0, 246.0, 217.0, 217.0, 217.0, 217.0, 217.0, 224.0, 214.0, 224.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 214.0, 235.0, 227.0, 227.0, 216.0, 216.0, 204.0, 204.0, 204.0, 208.0, 208.0, 206.0, 206.0, 206.0, 206.0, 206.0, 207.0, 224.0, 224.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 224.0, 227.0, 227.0, 227.0, 235.0, 235.0, 235.0, 235.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 235.0, 235.0, 215.0, 230.0, 234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 243.0, 233.0, 233.0, 225.0, 227.0, 217.0, 217.0, 227.0, 217.0, 219.0, 219.0, 226.0, 243.0, 243.0, 235.0, 235.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 238.0, 224.0, 224.0, 224.0, 214.0, 209.0, 209.0, 209.0, 223.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 218.0, 218.0, 220.0, 220.0, 220.0, 213.0, 213.0, 207.0, 204.0, 204.0, 204.0, 204.0, 212.0, 212.0, 212.0, 204.0, 204.0, 204.0, 204.0, 224.0, 224.0, 224.0, 214.0, 214.0, 213.0, 207.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 213.0, 213.0, 205.0, 211.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 224.0, 220.0, 220.0, 220.0, 220.0, 222.0, 219.0, 219.0, 222.0, 219.0, 219.0, 219.0, 219.0, 224.0, 224.0, 224.0, 224.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 223.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0]\n",
            "Min num_ones: 199.0\n",
            "[224.0, 224.0, 214.0, 224.0, 224.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 214.0, 224.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 207.0, 207.0, 238.0, 234.0, 236.0, 218.0, 214.0, 214.0, 204.0, 227.0, 226.0, 244.0, 244.0, 226.0, 226.0, 225.0, 225.0, 229.0, 225.0, 213.0, 207.0, 238.0, 238.0, 238.0, 238.0, 220.0, 220.0, 220.0, 220.0, 220.0, 227.0, 224.0, 224.0, 224.0, 210.0, 232.0, 210.0, 232.0, 237.0, 237.0, 237.0, 237.0, 236.0, 226.0, 222.0, 213.0, 207.0, 207.0, 238.0, 238.0, 238.0, 238.0, 228.0, 228.0, 228.0, 228.0, 229.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 207.0, 238.0, 227.0, 239.0, 213.0, 207.0, 207.0, 210.0, 210.0, 210.0, 210.0, 210.0, 212.0, 212.0, 210.0, 212.0, 224.0, 214.0, 224.0, 214.0, 224.0, 214.0, 225.0, 223.0, 225.0, 223.0, 225.0, 223.0, 213.0, 207.0, 207.0, 227.0, 227.0, 238.0, 238.0, 227.0, 227.0, 238.0, 238.0, 238.0, 213.0, 207.0, 238.0, 207.0, 238.0, 207.0, 238.0, 238.0, 207.0, 231.0, 227.0, 222.0, 235.0, 231.0, 225.0, 225.0, 225.0, 235.0, 223.0, 225.0, 227.0, 225.0, 218.0, 240.0, 240.0, 240.0, 240.0, 232.0, 240.0, 232.0, 232.0, 222.0, 222.0, 224.0, 227.0, 223.0, 223.0, 224.0, 224.0, 224.0, 235.0, 235.0, 235.0, 216.0, 226.0, 226.0, 226.0, 226.0, 226.0, 243.0, 226.0, 226.0, 243.0, 243.0, 213.0, 207.0, 204.0, 235.0, 235.0, 230.0, 230.0, 217.0, 229.0, 217.0, 217.0, 217.0, 229.0, 232.0, 218.0, 210.0, 221.0, 242.0, 221.0, 221.0, 242.0, 221.0, 221.0, 221.0, 242.0, 221.0, 229.0, 233.0, 226.0, 226.0, 226.0, 226.0, 211.0, 205.0, 205.0, 205.0, 211.0, 205.0, 205.0, 205.0, 205.0, 211.0, 205.0, 211.0, 224.0, 214.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 235.0, 223.0, 224.0, 232.0, 223.0, 221.0, 226.0, 233.0, 226.0, 226.0, 233.0, 226.0, 226.0, 219.0, 221.0, 221.0, 235.0, 232.0, 232.0, 235.0, 235.0, 232.0, 235.0, 235.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 226.0, 235.0, 235.0, 226.0, 238.0, 221.0, 238.0, 228.0, 228.0, 228.0, 228.0, 224.0, 224.0, 224.0, 244.0, 232.0, 224.0, 214.0, 224.0, 232.0, 218.0, 241.0, 224.0, 246.0, 224.0, 224.0, 224.0, 246.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 198.0, 219.0, 219.0, 219.0, 219.0, 198.0, 219.0, 205.0, 205.0, 200.0, 200.0, 223.0, 233.0, 224.0, 224.0, 238.0, 238.0, 236.0, 235.0, 235.0, 210.0, 230.0, 230.0, 221.0, 221.0, 221.0, 221.0, 222.0, 229.0, 238.0, 238.0, 224.0, 229.0, 219.0, 219.0, 219.0, 217.0, 219.0, 219.0, 219.0, 217.0, 219.0, 217.0, 217.0, 219.0, 219.0, 217.0, 224.0, 214.0, 214.0, 214.0, 233.0, 233.0, 231.0, 233.0, 233.0, 215.0, 215.0, 229.0, 213.0, 237.0, 237.0, 226.0, 245.0, 245.0, 245.0, 245.0, 245.0, 233.0, 224.0, 213.0, 213.0, 213.0, 213.0, 213.0, 207.0, 238.0, 207.0, 238.0, 225.0, 225.0, 227.0, 205.0, 205.0, 207.0, 238.0, 238.0, 207.0, 238.0, 238.0, 207.0, 208.0, 208.0, 213.0, 213.0, 221.0, 221.0, 221.0, 221.0, 229.0, 229.0, 228.0, 229.0, 229.0, 211.0, 209.0, 235.0, 209.0, 209.0, 235.0, 209.0, 224.0, 246.0, 240.0, 232.0, 224.0, 213.0, 240.0, 234.0, 234.0, 234.0, 226.0, 224.0, 242.0, 233.0, 221.0, 239.0, 231.0, 208.0, 198.0, 198.0, 231.0, 198.0, 198.0, 198.0, 231.0, 198.0, 198.0, 231.0, 231.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 224.0, 224.0, 224.0, 226.0, 230.0, 227.0, 226.0, 226.0, 195.0, 245.0, 228.0, 245.0, 222.0, 222.0, 222.0, 222.0, 240.0, 240.0, 224.0, 213.0, 207.0, 207.0, 239.0, 239.0, 228.0, 242.0, 242.0, 213.0, 242.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 238.0, 231.0, 233.0, 233.0, 242.0, 242.0, 242.0, 236.0, 221.0, 213.0, 213.0, 213.0, 213.0, 213.0, 207.0, 238.0, 238.0, 238.0, 238.0, 225.0, 227.0, 225.0, 225.0, 227.0, 227.0, 213.0, 213.0, 207.0, 238.0, 207.0, 207.0, 208.0, 204.0, 204.0, 203.0, 203.0, 226.0, 231.0, 216.0, 231.0, 216.0, 216.0, 223.0, 245.0, 245.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 224.0, 229.0, 229.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 229.0, 215.0, 217.0, 225.0, 225.0, 233.0, 224.0, 213.0, 221.0, 229.0, 229.0, 221.0, 229.0, 229.0, 221.0, 221.0, 219.0, 227.0, 224.0, 214.0, 240.0, 234.0, 239.0, 234.0, 239.0, 234.0, 239.0, 241.0, 239.0, 239.0, 224.0, 224.0, 224.0, 224.0, 224.0, 214.0, 214.0, 224.0, 231.0, 231.0, 224.0, 231.0, 224.0, 231.0, 224.0, 224.0, 213.0, 213.0, 213.0, 213.0, 207.0, 207.0, 238.0, 230.0, 230.0, 231.0, 228.0, 236.0, 228.0, 236.0, 227.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 238.0, 238.0, 238.0, 207.0, 213.0, 207.0, 222.0, 222.0, 239.0, 207.0, 239.0, 207.0, 207.0, 207.0, 239.0, 232.0, 224.0, 221.0, 221.0, 242.0, 242.0, 242.0, 221.0, 221.0, 242.0, 242.0, 240.0, 230.0, 241.0, 230.0, 219.0, 228.0, 228.0, 219.0, 231.0, 217.0, 233.0, 219.0, 219.0, 231.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 221.0, 211.0, 200.0, 200.0, 200.0, 200.0, 213.0, 211.0, 208.0, 200.0, 228.0, 229.0, 210.0, 224.0, 214.0, 224.0, 220.0, 204.0, 204.0, 204.0, 218.0, 218.0, 226.0, 224.0, 217.0, 224.0, 224.0, 217.0, 224.0, 214.0, 212.0, 212.0, 212.0, 212.0, 218.0, 212.0, 218.0, 212.0, 218.0, 218.0, 212.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 224.0, 214.0, 224.0, 224.0, 229.0, 220.0, 220.0, 220.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 217.0, 217.0, 217.0, 217.0, 225.0, 225.0, 217.0, 225.0, 234.0, 217.0, 227.0, 227.0, 227.0, 217.0, 227.0, 217.0, 217.0, 227.0, 227.0, 215.0, 240.0, 233.0, 233.0, 219.0, 219.0, 219.0, 219.0, 233.0, 219.0, 219.0, 224.0, 223.0, 223.0, 223.0, 223.0, 228.0, 233.0, 233.0, 228.0, 233.0, 233.0, 228.0, 224.0, 224.0, 231.0, 228.0, 228.0, 228.0, 220.0, 222.0, 222.0, 222.0, 222.0, 223.0, 221.0, 221.0, 229.0, 229.0, 229.0, 232.0, 224.0, 231.0, 231.0, 231.0, 228.0, 228.0, 241.0, 241.0, 228.0, 241.0, 241.0, 219.0, 217.0, 217.0, 210.0, 212.0, 212.0, 210.0, 210.0, 212.0, 210.0, 212.0, 210.0, 210.0, 212.0, 224.0, 228.0, 242.0, 242.0, 242.0, 231.0, 226.0, 244.0, 244.0, 226.0, 227.0, 224.0, 214.0, 224.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 224.0, 214.0, 224.0, 221.0, 210.0, 210.0, 215.0, 215.0, 215.0, 215.0, 221.0, 240.0, 240.0, 221.0, 221.0, 224.0, 224.0, 224.0, 214.0, 224.0, 214.0, 214.0, 214.0, 214.0, 224.0, 224.0, 214.0, 214.0, 214.0, 222.0, 225.0, 218.0, 238.0, 218.0, 218.0, 229.0, 217.0, 229.0, 217.0, 217.0, 217.0, 217.0, 229.0, 213.0, 213.0, 234.0, 234.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 231.0, 218.0, 222.0, 209.0, 222.0, 222.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 206.0, 223.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 213.0, 213.0, 217.0, 210.0, 208.0, 208.0, 208.0, 208.0, 208.0, 212.0, 212.0, 208.0, 212.0, 212.0, 212.0, 213.0, 207.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 212.0, 204.0, 204.0, 204.0, 204.0, 213.0, 213.0, 213.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 224.0, 224.0, 224.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 207.0, 207.0, 207.0]\n",
            "Min num_ones: 195.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-5c9e1d847df6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulated_annealing_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_ones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-d79966761cd2>\u001b[0m in \u001b[0;36msimulated_annealing_action\u001b[0;34m(m, N, state, num_ones, temperature)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0mmax_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mGF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgalois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mONES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_num_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0mGC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgood_cauchy_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-d79966761cd2>\u001b[0m in \u001b[0;36mget_num_ones\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mnum_ones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnum_ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/galois/_fields/_array.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, x, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;34m\"and instantiate an array using `x = GF(array_like)`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             )\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     def __init__(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/galois/_domains/_array.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, x, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Perform view without verification since the elements were verified in _verify_array_like_types_and_values()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/galois/_domains/_array.py\u001b[0m in \u001b[0;36m_view\u001b[0;34m(cls, array)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0muse\u001b[0m \u001b[0monly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_view_without_verification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = 3\n",
        "m = 3\n",
        "N = 2 ** w\n",
        "vec = [ i for i in range(N)]\n",
        "random.shuffle(vec)\n",
        "\n",
        "R = np.zeros((N, N))\n",
        "num_ones = []\n",
        "num_actions = m * m + 2 * m * N\n",
        "for i in range(num_actions):\n",
        "  environment = CauchyEnv(w, m, vec, num_ones)\n",
        "  time_step = environment.reset()\n",
        "  time_step = environment.step(i)\n",
        "  R[i//N][i%N] = time_step.reward\n",
        "\n",
        "print(num_ones)\n",
        "for i in range(N):\n",
        "  print(' '.join([f\"{R[i][j]:3.0f}\" for j in range(N)]))\n",
        "print(np.min(num_ones))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frzZx7ydhYYa",
        "outputId": "375287d0-eeff-4af8-dd91-e0dd6a961643"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32.0, 36.0, 34.0, 34.0, 36.0, 35.0, 34.0, 33.0, 32.0, 36.0, 32.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0]\n",
            "  3  -1   1   1  -1   0   1   2\n",
            "  3  -1   3   1   1   1   1   1\n",
            "  1   1   1   1   1   1   1   1\n",
            "  1   1   1   1   1   1   1   1\n",
            "  1   1   1   0   0   0   0   0\n",
            "  0   0   0   0   0   0   0   0\n",
            "  0   0   0   0   0   0   0   0\n",
            "  0   0   0   0   0   0   0   0\n",
            "32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = 4\n",
        "N = 5\n",
        "vec = [ i for i in range(2 ** W)]\n",
        "random.shuffle(vec)\n",
        "env = CauchyEnv(W, N, vec, num_ones)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "tf_policy = random_tf_policy.RandomTFPolicy(action_spec=tf_env.action_spec(),\n",
        "                                            time_step_spec=tf_env.time_step_spec())\n",
        "\n",
        "\n",
        "num_episodes = tf_metrics.NumberOfEpisodes()\n",
        "env_steps = tf_metrics.EnvironmentSteps()\n",
        "max_return = tf_metrics.MaxReturnMetric()\n",
        "replay_buffer = []\n",
        "observers = [num_episodes, env_steps, max_return, replay_buffer.append]\n",
        "driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
        "    tf_env, tf_policy, observers, num_episodes=100)\n",
        "\n",
        "# Initial driver.run will reset the environment and initialize the policy.\n",
        "final_time_step, policy_state = driver.run()\n",
        "\n",
        "print('final_time_step', final_time_step)\n",
        "print('Number of Steps: ', env_steps.result().numpy())\n",
        "print('Number of Episodes: ', num_episodes.result().numpy())\n",
        "print('Max Return: ', max_return.result().numpy())\n",
        "print('Min num_ones: ', np.min(num_ones))\n",
        "\n",
        "\n",
        "for epsilon in np.arange(0, 1.1, 0.1):\n",
        "  num_ones = []\n",
        "  environment = CauchyEnv(W, N, vec, num_ones)\n",
        "  tf_env = tf_py_environment.TFPyEnvironment(environment)\n",
        "\n",
        "  q_net = q_network.QNetwork(\n",
        "      tf_env.time_step_spec().observation,\n",
        "      tf_env.action_spec(),\n",
        "      fc_layer_params=(100,))\n",
        "\n",
        "  agent = dqn_agent.DqnAgent(\n",
        "      tf_env.time_step_spec(),\n",
        "      tf_env.action_spec(),\n",
        "      q_network=q_net,\n",
        "      epsilon_greedy=epsilon,\n",
        "      optimizer=tf.compat.v1.train.AdamOptimizer(1e-4))\n",
        "\n",
        "  collect_steps_per_iteration = 100\n",
        "  avg_return_metric = tf_metrics.AverageReturnMetric()\n",
        "  avg_episode_length_metric = tf_metrics.AverageEpisodeLengthMetric()\n",
        "  observers = [] #avg_return_metric, avg_episode_length_metric]\n",
        "  collect_op = dynamic_episode_driver.DynamicEpisodeDriver(\n",
        "    tf_env,\n",
        "    agent.collect_policy,\n",
        "    observers=observers,\n",
        "    num_episodes=collect_steps_per_iteration).run()\n",
        "\n",
        "  print(num_ones)\n",
        "  print(f\"Best num_ones with epsilon greedy={epsilon} is {np.min(num_ones)}\")\n",
        "  # print(f\"Avg return = {avg_return_metric.result().numpy()}\")\n",
        "  # print(f\"Avg episode length = {avg_episode_length_metric.result().numpy()}\")\n"
      ],
      "metadata": {
        "id": "BrP3Jthjt5KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "\n",
        "W = 8\n",
        "N = 10\n",
        "vec = [ i for i in range(2 ** W)]\n",
        "random.shuffle(vec)\n",
        "num_ones = []\n",
        "environment = CauchyEnv(W, N, vec, num_ones)\n",
        "tf_env = tf_py_environment.TFPyEnvironment(environment)\n",
        "\n",
        "eval_num_ones = []\n",
        "eval_environment = CauchyEnv(W, N, vec, eval_num_ones)\n",
        "tf_eval_env = tf_py_environment.TFPyEnvironment(eval_environment)\n",
        "\n",
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(tf_env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "# Define a helper function to create Dense layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def dense_layer(num_units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      num_units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    tf_env.time_step_spec(),\n",
        "    tf_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate))\n",
        "\n",
        "replay_buffer_capacity = 10000\n",
        "\n",
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    batch_size=tf_env.batch_size,\n",
        "    max_length=replay_buffer_capacity)\n",
        "replay_buffer.clear()\n",
        "\n",
        "# Add an observer that adds to the replay buffer:\n",
        "replay_observer = [replay_buffer.add_batch]\n",
        "\n",
        "collect_steps_per_iteration = 1000\n",
        "collect_op = dynamic_episode_driver.DynamicEpisodeDriver(\n",
        "  tf_env,\n",
        "  agent.collect_policy,\n",
        "  observers=replay_observer,\n",
        "  num_episodes=collect_steps_per_iteration).run()\n",
        "\n",
        "print(num_ones)\n",
        "print(f\"Best num_ones = {np.min(num_ones)}\")"
      ],
      "metadata": {
        "id": "3gWc157yFm6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.collect_policy._epsilon)"
      ],
      "metadata": {
        "id": "p3UtF9Jb_7H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_min_ones(environment, policy, num_ones, num_episodes=10):\n",
        "  total_num_ones = 0\n",
        "  actions = []\n",
        "  for _ in range(num_episodes):\n",
        "    time_step = environment.reset()\n",
        "    num_ones.clear()\n",
        "    actions.clear()\n",
        "    rewards_list = []\n",
        "    rewards = 0\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      rewards_list = np.concatenate((rewards_list, time_step.reward.numpy()))\n",
        "      rewards += time_step.reward\n",
        "      actions.append(action_step.action.numpy())\n",
        "    print(actions)\n",
        "    print(num_ones)\n",
        "    print(rewards.numpy())\n",
        "    print(rewards_list)\n",
        "    total_num_ones += np.min(num_ones)\n",
        "  return total_num_ones / num_episodes"
      ],
      "metadata": {
        "id": "jXtLQeJubp6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval = 100\n",
        "eval_interval = 100\n",
        "\n",
        "num_train_steps = 100\n",
        "df = pd.DataFrame()\n",
        "\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    sample_batch_size=10,\n",
        "    num_steps=2)\n",
        "iterator = iter(dataset)\n",
        "\n",
        "for step in range(num_train_steps):\n",
        "  trajectories, _ = next(iterator)\n",
        "  train_loss = agent.train(experience=trajectories).loss\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "  if step % eval_interval == 0:\n",
        "    min_ones = compute_min_ones(tf_eval_env, agent.collect_policy, eval_num_ones)\n",
        "    print('step = {0}: min_ones = {1}'.format(step, min_ones))\n",
        "  df = pd.concat([df, pd.DataFrame({'step': [step], 'min_ones': [min_ones], 'loss': [train_loss.numpy()]})])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Z9UmdfKlUgWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.policy)"
      ],
      "metadata": {
        "id": "huqkN22qd7wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('step', inplace=True)\n",
        "df['min_ones'].plot()"
      ],
      "metadata": {
        "id": "yyILya5RRyJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}